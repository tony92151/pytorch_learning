{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ID | GPU | MEM |\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import os\n",
    "import GPUtil\n",
    "GPUtil.showUtilization()\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SIGNSDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A standard PyTorch definition of Dataset which defines the functions __len__ and __getitem__.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform):\n",
    "        \"\"\"\n",
    "        Store the filenames of the jpgs to use. Specifies transforms to apply on images.\n",
    "        Args:\n",
    "            data_dir: (string) directory containing the dataset\n",
    "            transform: (torchvision.transforms) transformation to apply on image\n",
    "        \"\"\"\n",
    "        self.filenames = os.listdir(data_dir)\n",
    "        self.filenames = [os.path.join(data_dir, f) for f in self.filenames if f.endswith('.jpg')]\n",
    "\n",
    "        self.labels = [int(os.path.split(filename)[-1][0]) for filename in self.filenames]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch index idx image and labels from dataset. Perform transforms on image.\n",
    "        Args:\n",
    "            idx: (int) index in [0, 1, ..., size_of_dataset-1]\n",
    "        Returns:\n",
    "            image: (Tensor) transformed image\n",
    "            label: (int) corresponding label of image\n",
    "        \"\"\"\n",
    "        image = Image.open(self.filenames[idx])  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "train_data_path = \"dataset/train_signs/\"\n",
    "traindata = SIGNSDataset(train_data_path, train_transformer)\n",
    "\n",
    "dl = DataLoader(traindata, batch_size=32, shuffle=True,\n",
    "                                        num_workers=4,\n",
    "                                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # randomly flip image horizontally\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "test_data_path = \"dataset/test_signs/\"\n",
    "testdata = SIGNSDataset(train_data_path, train_transformer)\n",
    "\n",
    "tl = DataLoader(testdata, batch_size=32, shuffle=False,\n",
    "                                        num_workers=4,\n",
    "                                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "a,b = dl.dataset[0]\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the standard way to define your own network in PyTorch. You typically choose the components\n",
    "    (e.g. LSTMs, linear layers etc.) of your network in the __init__ function. You then apply these layers\n",
    "    on the input step-by-step in the forward function. You can use torch.nn.functional to apply functions\n",
    "    such as F.relu, F.sigmoid, F.softmax, F.max_pool2d. Be careful to ensure your dimensions are correct after each\n",
    "    step. You are encouraged to have a look at the network in pytorch/nlp/model/net.py to get a better sense of how\n",
    "    you can go about defining your own network.\n",
    "    The documentation for all the various components available o you is here: http://pytorch.org/docs/master/nn.html\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        self.num_channels = 32\n",
    "        \n",
    "        # each of the convolution layers below have the arguments (input_channels, output_channels, filter_size,\n",
    "        # stride, padding). We also include batch normalisation layers that help stabilise training.\n",
    "        # For more details on how to use these layers, check out the documentation.\n",
    "        self.conv1 = nn.Conv2d(3, self.num_channels, 3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(self.num_channels)\n",
    "        self.conv2 = nn.Conv2d(self.num_channels, self.num_channels*2, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(self.num_channels*2)\n",
    "        self.conv3 = nn.Conv2d(self.num_channels*2, self.num_channels*4, 3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(self.num_channels*4)\n",
    "\n",
    "        # 2 fully connected layers to transform the output of the convolution layers to the final output\n",
    "        self.fc1 = nn.Linear(8*8*self.num_channels*4, self.num_channels*4)\n",
    "        self.fcbn1 = nn.BatchNorm1d(self.num_channels*4)\n",
    "        self.fc2 = nn.Linear(self.num_channels*4, 6)       \n",
    "        self.dropout_rate = 0.8\n",
    "\n",
    "    def forward(self, s):\n",
    "\n",
    "        #                                                  -> batch_size x 3 x 64 x 64\n",
    "        # we apply the convolution layers, followed by batch normalisation, maxpool and relu x 3\n",
    "        s = self.bn1(self.conv1(s))                         # batch_size x num_channels x 64 x 64\n",
    "        s = F.relu(F.max_pool2d(s, 2))                      # batch_size x num_channels x 32 x 32\n",
    "        s = self.bn2(self.conv2(s))                         # batch_size x num_channels*2 x 32 x 32\n",
    "        s = F.relu(F.max_pool2d(s, 2))                      # batch_size x num_channels*2 x 16 x 16\n",
    "        s = self.bn3(self.conv3(s))                         # batch_size x num_channels*4 x 16 x 16\n",
    "        s = F.relu(F.max_pool2d(s, 2))                      # batch_size x num_channels*4 x 8 x 8\n",
    "\n",
    "        # flatten the output for each image\n",
    "        s = s.view(-1, 8*8*self.num_channels*4)             # batch_size x 8*8*num_channels*4\n",
    "\n",
    "        # apply 2 fully connected layers with dropout\n",
    "        s = F.dropout(F.relu(self.fcbn1(self.fc1(s))), \n",
    "            p=self.dropout_rate, training=self.training)    # batch_size x self.num_channels*4\n",
    "        s = self.fc2(s)                                     # batch_size x 6\n",
    "\n",
    "        # apply log softmax on each image's output (this is recommended over applying softmax\n",
    "        # since it is numerically more stable)\n",
    "        return F.log_softmax(s, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n",
      "  (fcbn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    cnn = Net().cuda()\n",
    "    print(\"Run in GPU\")\n",
    "else:\n",
    "    cnn = Net()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    for i, (train_batch, labels_batch) in enumerate(dl):\n",
    "        train_batch, labels_batch = train_batch.cuda(async=True), labels_batch.cuda(async=True)\n",
    "        # convert to torch Variables\n",
    "        train_batch, labels_batch = Variable(train_batch), Variable(labels_batch)\n",
    "\n",
    "        # compute model output and loss\n",
    "        output_batch = cnn(train_batch)\n",
    "        loss = loss_func(output_batch, labels_batch)\n",
    "        # clear previous gradients, compute gradients of all variables wrt loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # performs updates using calculated gradients\n",
    "        optimizer.step()\n",
    "        if i % 8 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, \n",
    "                    i * len(train_batch), len(dl.dataset),100. * i / len(dl), loss.data.item()))\n",
    "    print(\"Finish\")\n",
    "    GPUtil.showUtilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    cnn.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in tl:\n",
    "        data, target = Variable(data).cuda(), Variable(target).cuda()\n",
    "        output = cnn(data)\n",
    "        # sum up batch loss\n",
    "        los = loss_func(output, target)\n",
    "        #print(los)\n",
    "        test_loss += los\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    #print(test_loss)\n",
    "    test_loss /= len(tl)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'\n",
    "          .format(test_loss, correct, len(tl.dataset),\n",
    "        100. * correct / len(tl.dataset)))\n",
    "    \n",
    "    \n",
    "    #print(float(test_loss))\n",
    "    global Loss\n",
    "    global Accuracy\n",
    "    #Loss = np.append(Loss,float(test_loss))\n",
    "    #print(Loss)\n",
    "    #Accuracy = np.append(Accuracy,float(100. * correct / len(tl.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-582972d9f452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d59ece80ff6b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;31m# convert to torch Variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mtrain_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    159\u001b[0m         raise RuntimeError(\n\u001b[1;32m    160\u001b[0m             \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_isDriverSufficient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_isDriverSufficient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDriverVersion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,50):\n",
    "    if epoch == 1:\n",
    "        ts = time.time()\n",
    "    train(epoch)\n",
    "    test()\n",
    "te = time.time()\n",
    "print(\"Total cost %f sec\" % (te - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rospc/pytorch_g/lib/python3.5/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(cnn, 'cnn_stanford.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#single image test\n",
    "import matplotlib.pyplot as plt\n",
    "single_transforms = transforms.Compose(\n",
    "        [\n",
    "        transforms.Resize((64,64)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "        ]\n",
    ")\n",
    "model  = torch.load('cnn_stanford.pkl').cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n",
      "torch.Size([1, 3, 64, 64])\n",
      "(3, 64, 64)\n",
      "(64, 64, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = Image.open(\"image.jpg\")\n",
    "image = single_transforms(img).cpu()\n",
    "imgToShow = image.numpy()\n",
    "print(image.shape)\n",
    "image = image.unsqueeze(0)\n",
    "print(image.shape)\n",
    "\n",
    "print(imgToShow.shape)\n",
    "imgToShow = imgToShow.transpose((1, 2, 0))\n",
    "print(imgToShow.shape)\n",
    "plt.imshow(imgToShow, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "single_out = model(image)\n",
    "#print(single_out)\n",
    "p = torch.max(single_out, 1)[1].data.numpy().squeeze()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onnx to caffe2 \n",
    "batch_size=1  # 随便一个数\n",
    "x = Variable(torch.randn(batch_size,3,64,64), requires_grad=True).cuda()\n",
    "torch_out = torch.onnx._export(cnn, x, \"onnx/cnn_stanford.onnx\", export_params=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'graph torch-jit-export (\\n  %0[FLOAT, 1x3x64x64]\\n) initializers (\\n  %1[FLOAT, 32x3x3x3]\\n  %2[FLOAT, 32]\\n  %3[FLOAT, 32]\\n  %4[FLOAT, 32]\\n  %5[FLOAT, 32]\\n  %6[FLOAT, 32]\\n  %7[INT64, scalar]\\n  %8[FLOAT, 64x32x3x3]\\n  %9[FLOAT, 64]\\n  %10[FLOAT, 64]\\n  %11[FLOAT, 64]\\n  %12[FLOAT, 64]\\n  %13[FLOAT, 64]\\n  %14[INT64, scalar]\\n  %15[FLOAT, 128x64x3x3]\\n  %16[FLOAT, 128]\\n  %17[FLOAT, 128]\\n  %18[FLOAT, 128]\\n  %19[FLOAT, 128]\\n  %20[FLOAT, 128]\\n  %21[INT64, scalar]\\n  %22[FLOAT, 128x8192]\\n  %23[FLOAT, 128]\\n  %24[FLOAT, 128]\\n  %25[FLOAT, 128]\\n  %26[FLOAT, 128]\\n  %27[FLOAT, 128]\\n  %28[INT64, scalar]\\n  %29[FLOAT, 6x128]\\n  %30[FLOAT, 6]\\n) {\\n  %31 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%0, %1, %2)\\n  %32 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 1](%31, %3, %4, %5, %6)\\n  %33 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%32)\\n  %34 = Relu(%33)\\n  %35 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%34, %8, %9)\\n  %36 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 1](%35, %10, %11, %12, %13)\\n  %37 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%36)\\n  %38 = Relu(%37)\\n  %39 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%38, %15, %16)\\n  %40 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 1](%39, %17, %18, %19, %20)\\n  %41 = MaxPool[kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%40)\\n  %42 = Relu(%41)\\n  %43 = Constant[value = <Tensor>]()\\n  %44 = Reshape(%42, %43)\\n  %45 = Gemm[alpha = 1, beta = 1, transB = 1](%44, %22, %23)\\n  %46 = Unsqueeze[axes = [2]](%45)\\n  %47 = BatchNormalization[epsilon = 9.99999974737875e-06, momentum = 1](%46, %24, %25, %26, %27)\\n  %48 = Squeeze[axes = [2]](%47)\\n  %49 = Relu(%48)\\n  %50, %51 = Dropout[ratio = 0.800000011920929](%49)\\n  %52 = Gemm[alpha = 1, beta = 1, transB = 1](%50, %29, %30)\\n  %53 = LogSoftmax[axis = 1](%52)\\n  return %53\\n}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "# Load the ONNX model\n",
    "model = onnx.load(\"onnx/cnn_stanford.onnx\")\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(model)\n",
    "# Print a human readable representation of the graph\n",
    "onnx.helper.printable_graph(model.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CUDA operators do not support 64-bit doubles, please use arr.astype(np.float32) or np.int32 for ints. Blob: 0 type: float64\n"
     ]
    }
   ],
   "source": [
    "# ...continuing from above\n",
    "import caffe2.python.onnx.backend as backend\n",
    "import numpy as np\n",
    "\n",
    "rep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\"\n",
    "# For the Caffe2 backend:\n",
    "#     rep.predict_net is the Caffe2 protobuf for the network\n",
    "#     rep.workspace is the Caffe2 workspace for the network\n",
    "#       (see the class caffe2.python.onnx.backend.Workspace)\n",
    "outputs = rep.run(np.random.randn(10, 3, 64, 64).astype(np.float32))\n",
    "# To run networks with more than one input, pass a tuple\n",
    "# rather than a single numpy ndarray.\n",
    "\n",
    "from caffe2.python.onnx.backend import Caffe2Backend as c2\n",
    "init_net, predict_net = c2.onnx_graph_to_caffe2_net(model)\n",
    "with open(\"onnx/init_net.pb\", \"wb\") as f:\n",
    "    f.write(init_net.SerializeToString())\n",
    "with open(\"onnx/predict_net.pb\", \"wb\") as f:\n",
    "    f.write(predict_net.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
